{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbbad11",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4607b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953ffed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from loguru import logger as lg\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "from rich import get_console\n",
    "\n",
    "# Rich Jupyter fix\n",
    "console: Console = get_console()\n",
    "console.is_jupyter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snap_fit.config.aruco.aruco_board_config import ArucoBoardConfig\n",
    "from snap_fit.config.aruco.aruco_detector_config import ArucoDetectorConfig\n",
    "from snap_fit.params.snap_fit_params import get_snap_fit_paths\n",
    "from snap_fit.puzzle.sheet_aruco import SheetAruco\n",
    "from snap_fit.puzzle.sheet_manager import SheetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9524597d",
   "metadata": {},
   "source": [
    "## Helper: Load Puzzle Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0c72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_puzzle_sheets(puzzle_name: str) -> SheetManager:\n",
    "    \"\"\"Load puzzle sheets for a given puzzle name (e.g., 'sample_puzzle_v1').\"\"\"\n",
    "    # Configure ArUco detection\n",
    "    board_config = ArucoBoardConfig(\n",
    "        markers_x=7,\n",
    "        markers_y=5,\n",
    "        marker_length=100,\n",
    "        marker_separation=100,\n",
    "    )\n",
    "    detector_config = ArucoDetectorConfig(board=board_config)\n",
    "\n",
    "    # Initialize sheet loader\n",
    "    sheet_aruco = SheetAruco(detector_config)\n",
    "    aruco_loader = partial(sheet_aruco.load_sheet, min_area=5_000)\n",
    "\n",
    "    # Load puzzle sheets\n",
    "    paths = get_snap_fit_paths()\n",
    "    data_dir = paths.data_fol / puzzle_name / \"sheets\"\n",
    "    lg.info(f\"Loading data from {data_dir}\")\n",
    "\n",
    "    manager = SheetManager()\n",
    "    manager.add_sheets(\n",
    "        folder_path=data_dir,\n",
    "        pattern=\"*.png\",\n",
    "        loader_func=aruco_loader,\n",
    "    )\n",
    "\n",
    "    lg.info(\n",
    "        f\"Loaded {len(manager.get_sheets_ls())} sheets with \"\n",
    "        f\"{len(manager.get_pieces_ls())} pieces\"\n",
    "    )\n",
    "    return manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a10c00",
   "metadata": {},
   "source": [
    "## Load v1 and v2 Puzzle Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75f1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_v1 = load_puzzle_sheets(\"sample_puzzle_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c9ab50",
   "metadata": {},
   "outputs": [],
   "source": [
    "manager_v2 = load_puzzle_sheets(\"sample_puzzle_v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce1c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute expected segment counts for a 6x8 puzzle\n",
    "ROWS, COLS = 6, 8\n",
    "\n",
    "total_pieces = ROWS * COLS  # 48\n",
    "total_segments = total_pieces * 4  # 192\n",
    "\n",
    "# EDGE segments are on the puzzle boundary (perimeter)\n",
    "perimeter_segments = 2 * (ROWS + COLS)  # 28\n",
    "\n",
    "# Internal segments should be IN or OUT (each internal edge has one of each)\n",
    "internal_horizontal_edges = ROWS * (COLS - 1)  # 42\n",
    "internal_vertical_edges = (ROWS - 1) * COLS  # 40\n",
    "total_internal_edges = internal_horizontal_edges + internal_vertical_edges  # 82\n",
    "\n",
    "# Each internal edge contributes one IN and one OUT segment\n",
    "expected_in = total_internal_edges  # 82\n",
    "expected_out = total_internal_edges  # 82\n",
    "expected_edge = perimeter_segments  # 28\n",
    "expected_weird = 0  # ideally none!\n",
    "\n",
    "rprint(\"[bold]Expected Segment Distribution for 6x8 Puzzle[/bold]\")\n",
    "rprint(f\"  Total segments: {total_segments}\")\n",
    "rprint(\n",
    "    f\"  EDGE (boundary): {expected_edge} ({100 * expected_edge / total_segments:.1f}%)\"\n",
    ")\n",
    "rprint(f\"  IN:   {expected_in} ({100 * expected_in / total_segments:.1f}%)\")\n",
    "rprint(f\"  OUT:  {expected_out} ({100 * expected_out / total_segments:.1f}%)\")\n",
    "rprint(f\"  WEIRD (target): {expected_weird} (0.0%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329023c4",
   "metadata": {},
   "source": [
    "## Analyze Shape Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9552afad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_shapes(manager: SheetManager, label: str) -> Counter:\n",
    "    \"\"\"Count segment shapes across all pieces.\"\"\"\n",
    "    shapes = []\n",
    "    for piece in manager.get_pieces_ls():\n",
    "        for seg in piece.segments.values():\n",
    "            shapes.append(seg.shape)\n",
    "\n",
    "    counts = Counter(shapes)\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    rprint(f\"\\n[bold]{label}[/bold]\")\n",
    "    rprint(f\"  Total segments: {total}\")\n",
    "    for shape, count in counts.most_common():\n",
    "        pct = 100 * count / total\n",
    "        rprint(f\"  {shape.name:>6}: {count:>3} ({pct:5.1f}%)\")\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0559f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_v1 = analyze_shapes(manager_v1, \"sample_puzzle_v1\")\n",
    "counts_v2 = analyze_shapes(manager_v2, \"sample_puzzle_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3234d1c8",
   "metadata": {},
   "source": [
    "## Visualize WEIRD Segments\n",
    "\n",
    "Let's look at segments classified as WEIRD to understand the failure mode.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4ff32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snap_fit.image.segment import SegmentShape\n",
    "\n",
    "\n",
    "def get_weird_segments(manager: SheetManager, max_count: int = 10):\n",
    "    \"\"\"Get a sample of WEIRD segments for visualization.\"\"\"\n",
    "    weird_segments = []\n",
    "    for piece in manager.get_pieces_ls():\n",
    "        for seg_id, seg in piece.segments.items():\n",
    "            if seg.shape == SegmentShape.WEIRD:\n",
    "                weird_segments.append((piece.piece_id, seg_id, seg))\n",
    "                if len(weird_segments) >= max_count:\n",
    "                    return weird_segments\n",
    "    return weird_segments\n",
    "\n",
    "\n",
    "weird_v1 = get_weird_segments(manager_v1, max_count=6)\n",
    "rprint(f\"Found {len(weird_v1)} WEIRD segments to analyze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a736ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_segment_points(seg, ax, title: str):\n",
    "    \"\"\"Plot segment points showing the classification problem.\"\"\"\n",
    "    # seg.points has shape (N, 1, 2) - OpenCV contour format\n",
    "    pts = seg.points.squeeze()  # Now (N, 2)\n",
    "\n",
    "    # Plot raw points\n",
    "    ax.plot(pts[:, 0], pts[:, 1], \"b-\", linewidth=2, label=\"Segment\")\n",
    "    ax.scatter(pts[0, 0], pts[0, 1], c=\"green\", s=100, zorder=5, label=\"Start\")\n",
    "    ax.scatter(pts[-1, 0], pts[-1, 1], c=\"red\", s=100, zorder=5, label=\"End\")\n",
    "\n",
    "    ax.set_title(f\"{title}\\nShape: {seg.shape.name}\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.legend(fontsize=8)\n",
    "    ax.grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d724cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize WEIRD segments\n",
    "if weird_v1:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i, (piece_id, seg_id, seg) in enumerate(weird_v1[:6]):\n",
    "        plot_segment_points(seg, axes[i], f\"Piece {piece_id}, Seg {seg_id}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd984644",
   "metadata": {},
   "source": [
    "## Analyze Point Distribution (Understanding the Classification)\n",
    "\n",
    "The current algorithm counts points beyond `flat_th=20` on each side of the center line.\n",
    "Let's see the actual distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41979ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_segment_distribution(seg):\n",
    "    \"\"\"Analyze segment point distribution relative to center line.\n",
    "\n",
    "    Returns dict with statistics about point distribution.\n",
    "    \"\"\"\n",
    "    # seg.points has shape (N, 1, 2) - OpenCV contour format\n",
    "    pts = seg.points.squeeze()  # Now (N, 2)\n",
    "\n",
    "    # Transform to align start-end with x-axis (mimicking _compute_shape)\n",
    "    start, end = pts[0], pts[-1]\n",
    "    direction = end - start\n",
    "    length = np.linalg.norm(direction)\n",
    "\n",
    "    if length < 1e-6:\n",
    "        return None\n",
    "\n",
    "    # Rotation to align with x-axis\n",
    "    angle = np.arctan2(direction[1], direction[0])\n",
    "    cos_a, sin_a = np.cos(-angle), np.sin(-angle)\n",
    "\n",
    "    # Transform points\n",
    "    centered = pts - start\n",
    "    rotated = np.column_stack(\n",
    "        [\n",
    "            centered[:, 0] * cos_a - centered[:, 1] * sin_a,\n",
    "            centered[:, 0] * sin_a + centered[:, 1] * cos_a,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Y values are perpendicular distances from center line\n",
    "    y_vals = rotated[:, 1]\n",
    "\n",
    "    # Current thresholds\n",
    "    flat_th = 20\n",
    "    count_th = 5\n",
    "\n",
    "    out_count = (y_vals < -flat_th).sum()  # Points below line\n",
    "    in_count = (y_vals > flat_th).sum()  # Points above line\n",
    "\n",
    "    return {\n",
    "        \"shape\": seg.shape,\n",
    "        \"y_vals\": y_vals,\n",
    "        \"mean_y\": np.mean(y_vals),\n",
    "        \"std_y\": np.std(y_vals),\n",
    "        \"min_y\": np.min(y_vals),\n",
    "        \"max_y\": np.max(y_vals),\n",
    "        \"out_count\": out_count,\n",
    "        \"in_count\": in_count,\n",
    "        \"is_weird\": out_count > count_th and in_count > count_th,\n",
    "        \"signed_area\": np.trapz(y_vals),\n",
    "        \"length\": length,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f283f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze all segments\n",
    "all_stats_v1 = []\n",
    "for piece in manager_v1.get_pieces_ls():\n",
    "    for seg_id, seg in piece.segments.items():\n",
    "        stats = analyze_segment_distribution(seg)\n",
    "        if stats:\n",
    "            stats[\"piece_id\"] = piece.piece_id\n",
    "            stats[\"seg_id\"] = seg_id\n",
    "            all_stats_v1.append(stats)\n",
    "\n",
    "rprint(f\"Analyzed {len(all_stats_v1)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2857164b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare distributions by shape type\n",
    "from snap_fit.image.segment import SegmentShape\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "shape_types = [SegmentShape.IN, SegmentShape.OUT, SegmentShape.EDGE, SegmentShape.WEIRD]\n",
    "colors = [\"blue\", \"green\", \"orange\", \"red\"]\n",
    "\n",
    "for ax, shape, color in zip(axes.flatten(), shape_types, colors):\n",
    "    shape_stats = [s for s in all_stats_v1 if s[\"shape\"] == shape]\n",
    "\n",
    "    if shape_stats:\n",
    "        mean_ys = [s[\"mean_y\"] for s in shape_stats]\n",
    "        signed_areas = [s[\"signed_area\"] for s in shape_stats]\n",
    "\n",
    "        ax.scatter(mean_ys, signed_areas, c=color, alpha=0.6, s=50)\n",
    "        ax.axhline(y=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "        ax.axvline(x=0, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    ax.set_title(f\"{shape.name} (n={len(shape_stats)})\")\n",
    "    ax.set_xlabel(\"Mean Y (perpendicular displacement)\")\n",
    "    ax.set_ylabel(\"Signed Area\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b427e",
   "metadata": {},
   "source": [
    "## Compare Classification Approaches\n",
    "\n",
    "Let's test alternative classification methods on the existing data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127ca53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_mean(stats, threshold=10):\n",
    "    \"\"\"Option B: Classify by mean displacement.\"\"\"\n",
    "    mean_y = stats[\"mean_y\"]\n",
    "    if mean_y < -threshold:\n",
    "        return \"OUT\"\n",
    "    elif mean_y > threshold:\n",
    "        return \"IN\"\n",
    "    else:\n",
    "        return \"EDGE\"\n",
    "\n",
    "\n",
    "def classify_by_area(stats, threshold=500):\n",
    "    \"\"\"Option B: Classify by signed area.\"\"\"\n",
    "    area = stats[\"signed_area\"]\n",
    "    if area < -threshold:\n",
    "        return \"OUT\"\n",
    "    elif area > threshold:\n",
    "        return \"IN\"\n",
    "    else:\n",
    "        return \"EDGE\"\n",
    "\n",
    "\n",
    "def classify_adaptive(stats):\n",
    "    \"\"\"Option A: Adaptive thresholds based on segment stats.\"\"\"\n",
    "    y_vals = stats[\"y_vals\"]\n",
    "    flat_th = max(10, np.std(y_vals) * 1.5)\n",
    "    count_th = max(3, len(y_vals) * 0.05)\n",
    "\n",
    "    out_count = (y_vals < -flat_th).sum()\n",
    "    in_count = (y_vals > flat_th).sum()\n",
    "\n",
    "    # Convert numpy bools to Python bools for pattern matching\n",
    "    is_out = bool(out_count > count_th)\n",
    "    is_in = bool(in_count > count_th)\n",
    "\n",
    "    match (is_out, is_in):\n",
    "        case (True, False):\n",
    "            return \"OUT\"\n",
    "        case (False, True):\n",
    "            return \"IN\"\n",
    "        case (False, False):\n",
    "            return \"EDGE\"\n",
    "        case (True, True):\n",
    "            return \"WEIRD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7f893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classification methods\n",
    "methods = {\n",
    "    \"Current\": lambda s: s[\"shape\"].name,\n",
    "    \"Mean (th=10)\": lambda s: classify_by_mean(s, threshold=10),\n",
    "    \"Mean (th=15)\": lambda s: classify_by_mean(s, threshold=15),\n",
    "    \"Area (th=50)\": lambda s: classify_by_area(s, threshold=50),\n",
    "    \"Area (th=500)\": lambda s: classify_by_area(s, threshold=500),\n",
    "    \"Area (th=1000)\": lambda s: classify_by_area(s, threshold=1000),\n",
    "    \"Adaptive\": classify_adaptive,\n",
    "}\n",
    "\n",
    "rprint(\"\\n[bold]Classification Method Comparison (v1)[/bold]\")\n",
    "if not all_stats_v1:\n",
    "    rprint(\"[red]No stats available - rerun previous cells[/red]\")\n",
    "else:\n",
    "    for method_name, classify_fn in methods.items():\n",
    "        classifications = [classify_fn(s) for s in all_stats_v1]\n",
    "        counts = Counter(classifications)\n",
    "        total = len(classifications)\n",
    "        weird_pct = 100 * counts.get(\"WEIRD\", 0) / total if total > 0 else 0\n",
    "        rprint(\n",
    "            f\"  {method_name:15s}: WEIRD={counts.get('WEIRD', 0):>3} ({weird_pct:5.1f}%), \"\n",
    "            f\"IN={counts.get('IN', 0):>3}, OUT={counts.get('OUT', 0):>3}, EDGE={counts.get('EDGE', 0):>3}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e0b27",
   "metadata": {},
   "source": [
    "## Summary & Next Steps\n",
    "\n",
    "Based on this exploration:\n",
    "\n",
    "- Current WEIRD count: ???\n",
    "- Best alternative method: ???\n",
    "\n",
    "**Decision needed**: Which approach to implement?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snap-fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
