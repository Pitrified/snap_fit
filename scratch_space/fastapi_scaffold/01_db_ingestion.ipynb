{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67cefc7d",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2c260",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180c99ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from rich import print as rprint\n",
    "from loguru import logger as lg\n",
    "\n",
    "from snap_fit.puzzle.sheet import Sheet\n",
    "from snap_fit.puzzle.sheet_manager import SheetManager\n",
    "from snap_fit.puzzle.piece_matcher import PieceMatcher\n",
    "from snap_fit.data_models import SheetRecord, PieceRecord, MatchResult, PieceId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "REPO_ROOT = Path.cwd().parent.parent\n",
    "DATA_ROOT = REPO_ROOT / \"data\" / \"sample\"\n",
    "OUTPUT_DIR = Path.cwd() / \"output\"\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "METADATA_PATH = OUTPUT_DIR / \"metadata.json\"\n",
    "CONTOUR_CACHE_DIR = OUTPUT_DIR / \"contour_cache\"\n",
    "MATCHES_PATH = OUTPUT_DIR / \"matches.json\"\n",
    "\n",
    "rprint(f\"Data root: {DATA_ROOT}\")\n",
    "rprint(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7e452",
   "metadata": {},
   "source": [
    "## Phase 1: Load Sheets from Images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb07d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available sample images\n",
    "sample_images = sorted(DATA_ROOT.glob(\"*.jpg\")) + sorted(DATA_ROOT.glob(\"*.png\"))\n",
    "rprint(f\"Found {len(sample_images)} sample images:\")\n",
    "for img in sample_images[:5]:\n",
    "    rprint(f\"  - {img.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbae0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load sheets\n",
    "manager = SheetManager()\n",
    "\n",
    "\n",
    "def load_sheet(path: Path) -> Sheet:\n",
    "    \"\"\"Load a sheet from an image file.\"\"\"\n",
    "    return Sheet(img_fp=path, min_area=50_000)\n",
    "\n",
    "\n",
    "# Load first few images for testing\n",
    "for img_path in sample_images[:3]:  # Limit for quick test\n",
    "    sheet = load_sheet(img_path)\n",
    "    manager.add_sheet(sheet, img_path.stem)\n",
    "\n",
    "rprint(f\"Loaded {len(manager.sheets)} sheets\")\n",
    "rprint(f\"Total pieces: {len(manager.get_pieces_ls())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4742e9",
   "metadata": {},
   "source": [
    "## Phase 2: Save Metadata + Contour Cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata JSON\n",
    "manager.save_metadata(METADATA_PATH, data_root=DATA_ROOT)\n",
    "rprint(f\"Metadata saved to: {METADATA_PATH}\")\n",
    "rprint(f\"File size: {METADATA_PATH.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7b5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save contour cache\n",
    "manager.save_contour_cache(CONTOUR_CACHE_DIR)\n",
    "rprint(f\"Contour cache saved to: {CONTOUR_CACHE_DIR}\")\n",
    "\n",
    "# List cache files\n",
    "cache_files = list(CONTOUR_CACHE_DIR.glob(\"*\"))\n",
    "for f in cache_files:\n",
    "    rprint(f\"  - {f.name}: {f.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faf9e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect metadata structure\n",
    "import json\n",
    "\n",
    "metadata = json.loads(METADATA_PATH.read_text())\n",
    "rprint(f\"Metadata keys: {list(metadata.keys())}\")\n",
    "rprint(f\"Sheets: {len(metadata['sheets'])}\")\n",
    "rprint(f\"Pieces: {len(metadata['pieces'])}\")\n",
    "\n",
    "# Show first sheet record\n",
    "rprint(\"\\nFirst sheet record:\")\n",
    "rprint(metadata[\"sheets\"][0])\n",
    "\n",
    "# Show first piece record\n",
    "rprint(\"\\nFirst piece record:\")\n",
    "rprint(metadata[\"pieces\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d5da8e",
   "metadata": {},
   "source": [
    "## Phase 3: Run Matching and Save Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848ef059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run matching\n",
    "matcher = PieceMatcher(manager)\n",
    "matcher.match_all()\n",
    "\n",
    "rprint(f\"Total matches: {len(matcher.results)}\")\n",
    "rprint(f\"Top 5 matches:\")\n",
    "for m in matcher.get_top_matches(5):\n",
    "    rprint(f\"  {m.seg_id1} <-> {m.seg_id2}: {m.similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfcd972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save matches\n",
    "matcher.save_matches_json(MATCHES_PATH)\n",
    "rprint(f\"Matches saved to: {MATCHES_PATH}\")\n",
    "rprint(f\"File size: {MATCHES_PATH.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfd528e",
   "metadata": {},
   "source": [
    "## Phase 4: Reload and Verify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09281457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload metadata (records only, no full objects)\n",
    "loaded_metadata = SheetManager.load_metadata(METADATA_PATH)\n",
    "\n",
    "rprint(f\"Loaded {len(loaded_metadata['sheets'])} sheet records\")\n",
    "rprint(f\"Loaded {len(loaded_metadata['pieces'])} piece records\")\n",
    "\n",
    "# Validate as Pydantic models\n",
    "sheet_records = [SheetRecord.model_validate(s) for s in loaded_metadata[\"sheets\"]]\n",
    "piece_records = [PieceRecord.model_validate(p) for p in loaded_metadata[\"pieces\"]]\n",
    "\n",
    "rprint(f\"\\nValidated {len(sheet_records)} SheetRecords\")\n",
    "rprint(f\"Validated {len(piece_records)} PieceRecords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ceab2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test contour cache loading\n",
    "if piece_records:\n",
    "    test_piece_id = piece_records[0].piece_id\n",
    "    contour, corners = SheetManager.load_contour_for_piece(\n",
    "        test_piece_id, CONTOUR_CACHE_DIR\n",
    "    )\n",
    "\n",
    "    rprint(f\"Loaded contour for {test_piece_id}:\")\n",
    "    rprint(f\"  Shape: {contour.shape}\")\n",
    "    rprint(f\"  Points: {len(contour)}\")\n",
    "    rprint(f\"  Corner indices: {corners}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2be4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload matches into a fresh matcher\n",
    "matcher2 = PieceMatcher(manager)\n",
    "matcher2.load_matches_json(MATCHES_PATH)\n",
    "\n",
    "rprint(f\"Loaded {len(matcher2.results)} matches\")\n",
    "rprint(f\"Lookup cache size: {len(matcher2._lookup)}\")\n",
    "\n",
    "# Verify data integrity\n",
    "assert len(matcher2.results) == len(matcher.results), \"Match count mismatch!\"\n",
    "\n",
    "# Compare top matches\n",
    "orig_top = matcher.get_top_matches(5)\n",
    "loaded_top = matcher2.get_top_matches(5)\n",
    "\n",
    "rprint(\"\\nTop 5 matches comparison:\")\n",
    "for orig, loaded in zip(orig_top, loaded_top):\n",
    "    match_ok = orig.seg_id1 == loaded.seg_id1 and orig.similarity == loaded.similarity\n",
    "    status = \"✅\" if match_ok else \"❌\"\n",
    "    rprint(f\"  {status} {orig.similarity:.4f} vs {loaded.similarity:.4f}\")\n",
    "\n",
    "rprint(\"\\n✅ Round-trip validation passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e686250d",
   "metadata": {},
   "source": [
    "## Phase 5: Test Incremental Matching\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df667d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate adding a new sheet\n",
    "if len(sample_images) > 3:\n",
    "    new_img = sample_images[3]\n",
    "    new_sheet = load_sheet(new_img)\n",
    "    manager.add_sheet(new_sheet, new_img.stem)\n",
    "\n",
    "    # Get piece IDs from the new sheet\n",
    "    new_piece_ids = [p.piece_id for p in new_sheet.pieces]\n",
    "    rprint(f\"Added new sheet: {new_img.stem}\")\n",
    "    rprint(f\"New pieces: {len(new_piece_ids)}\")\n",
    "\n",
    "    # Run incremental matching\n",
    "    matches_before = len(matcher2.results)\n",
    "    new_matches = matcher2.match_incremental(new_piece_ids)\n",
    "    matches_after = len(matcher2.results)\n",
    "\n",
    "    rprint(f\"\\nMatches before: {matches_before}\")\n",
    "    rprint(f\"New matches added: {new_matches}\")\n",
    "    rprint(f\"Matches after: {matches_after}\")\n",
    "else:\n",
    "    rprint(\"Not enough sample images for incremental test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9c2c56",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb121a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary stats\n",
    "rprint(\"=\" * 50)\n",
    "rprint(\"PERSISTENCE SUMMARY\")\n",
    "rprint(\"=\" * 50)\n",
    "rprint(f\"Sheets loaded: {len(manager.sheets)}\")\n",
    "rprint(f\"Total pieces: {len(manager.get_pieces_ls())}\")\n",
    "rprint(f\"Total matches: {len(matcher2.results)}\")\n",
    "rprint(f\"\\nFile sizes:\")\n",
    "rprint(f\"  Metadata JSON: {METADATA_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "rprint(f\"  Matches JSON: {MATCHES_PATH.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "total_cache = sum(f.stat().st_size for f in CONTOUR_CACHE_DIR.glob(\"*\"))\n",
    "rprint(f\"  Contour cache: {total_cache / 1024:.1f} KB\")\n",
    "rprint(\"\\n✅ All persistence methods working correctly!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
