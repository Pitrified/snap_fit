{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. translate one segment so that the ends are over the first one\n",
    "2. compute some sort of distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger as lg\n",
    "from rich import get_console\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "\n",
    "# some magic to make rich work in jupyter\n",
    "# https://github.com/Textualize/rich/issues/3483\n",
    "# enable it for every cell output with %load_ext rich\n",
    "console: Console = get_console()\n",
    "console.is_jupyter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from snap_fit.config.aruco.aruco_board_config import ArucoBoardConfig\n",
    "from snap_fit.config.aruco.aruco_detector_config import ArucoDetectorConfig\n",
    "from snap_fit.config.types import EDGE_ENDS_TO_CORNER\n",
    "from snap_fit.config.types import EdgePos\n",
    "from snap_fit.image.process import estimate_affine_transform\n",
    "from snap_fit.image.process import find_contours\n",
    "from snap_fit.image.process import find_corners\n",
    "from snap_fit.image.process import transform_contour\n",
    "from snap_fit.image.segment import Segment\n",
    "from snap_fit.image.segment_matcher import SegmentMatcher\n",
    "from snap_fit.image.utils import draw_contour\n",
    "from snap_fit.image.utils import draw_corners\n",
    "from snap_fit.image.utils import show_image_mpl\n",
    "from snap_fit.params.snap_fit_params import get_snap_fit_paths\n",
    "from snap_fit.puzzle.piece import Piece\n",
    "from snap_fit.puzzle.sheet import Sheet\n",
    "from snap_fit.puzzle.sheet_aruco import SheetAruco\n",
    "from snap_fit.puzzle.sheet_manager import SheetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure ArUco Board and Detector\n",
    "# Using defaults which match the printed board used for 'data/oca'\n",
    "board_config = ArucoBoardConfig(markers_x=5, markers_y=7)\n",
    "detector_config = ArucoDetectorConfig(board=board_config)\n",
    "\n",
    "# 2. Initialize SheetAruco helper\n",
    "# crop_margin is automatically calculated from the detector configuration\n",
    "sheet_aruco = SheetAruco(detector_config)\n",
    "\n",
    "# 3. Define the loader function\n",
    "# SheetAruco.load_sheet handles loading, rectification, and Sheet creation\n",
    "aruco_loader = sheet_aruco.load_sheet\n",
    "\n",
    "# 4. define base folder\n",
    "paths = get_snap_fit_paths()\n",
    "data_dir = paths.data_fol / \"oca\"\n",
    "lg.info(f\"Loading data from {data_dir}\")\n",
    "\n",
    "# 5. instantiate manager and load\n",
    "manager = SheetManager()\n",
    "manager.add_sheets(folder_path=data_dir, pattern=\"*.jpg\", loader_func=aruco_loader)\n",
    "\n",
    "# Verify Sheets\n",
    "sheets = manager.get_sheets_ls()\n",
    "print(f\"Managed Sheets: {len(sheets)}\")\n",
    "for sheet in sheets:\n",
    "    print(f\" - {sheet.img_fp.name}: {len(sheet.pieces)} pieces\")\n",
    "\n",
    "# Verify Pieces\n",
    "pieces = manager.get_pieces_ls()\n",
    "print(f\"Total Pieces: {len(pieces)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pieces and segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_index = 1\n",
    "p2_index = 3\n",
    "\n",
    "s1_type = EdgePos.LEFT\n",
    "s2_type = EdgePos.BOTTOM\n",
    "\n",
    "p1 = pieces[p1_index]\n",
    "p2 = pieces[p2_index]\n",
    "rprint(f\"using {p1.name} and {p2.name}\")\n",
    "\n",
    "seg1 = p1.contour.segments[s1_type]\n",
    "seg2 = p2.contour.segments[s2_type]\n",
    "\n",
    "# 02_PXL_20251207_204130904 has index 1; left is clear edge\n",
    "# 01_PXL_20251207_204113818 has index 3; should match on bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_contour_seg = p1.img_bw.copy() // 10\n",
    "for _ei, edge_name in enumerate(EdgePos):\n",
    "    segment = p1.contour.segments[edge_name]\n",
    "    points = segment.points\n",
    "    color = 250 if edge_name == s1_type else 120\n",
    "    draw_contour(img_contour_seg, points, color=color)\n",
    "show_image_mpl(img_contour_seg, figsize=(5, 5))\n",
    "\n",
    "img_contour_seg = p2.img_bw.copy() // 10\n",
    "for _ei, edge_name in enumerate(EdgePos):\n",
    "    segment = p2.contour.segments[edge_name]\n",
    "    points = segment.points\n",
    "    color = 250 if edge_name == s2_type else 120\n",
    "    draw_contour(img_contour_seg, points, color=color)\n",
    "show_image_mpl(img_contour_seg, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a segment matcher so that s1 points get transformed\n",
    "seg_match = SegmentMatcher(seg1, seg2)\n",
    "\n",
    "sim = seg_match.compute_similarity()\n",
    "rprint(f\"got {sim=:.2f}\")\n",
    "\n",
    "# draw the internal segments\n",
    "p2_img = p2.img_bw.copy() // 10\n",
    "draw_contour(p2_img, seg_match.s2.points, color=120)\n",
    "draw_contour(p2_img, seg_match.s1_points_transformed, color=120)\n",
    "show_image_mpl(p2_img, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the ratio to account for different segment lengths\n",
    "s1_len = len(seg_match.s1)\n",
    "s2_len = len(seg_match.s2)\n",
    "ratio = s2_len / s1_len\n",
    "rprint(f\"using {s1_len=} {s2_len=} {ratio=:.2f}\")\n",
    "\n",
    "# compute the similarity\n",
    "tot_dist: float = 0\n",
    "for i1 in range(s1_len):\n",
    "    i2 = floor(i1 * ratio)\n",
    "    p1 = seg_match.s1_points_transformed[i1][0]\n",
    "    p2 = seg_match.s2.points[s2_len - i2 - 1][0]  # !!!\n",
    "    dist = np.linalg.norm(p1 - p2)\n",
    "    tot_dist += dist  # type: ignore - numpy floating to float\n",
    "    if i1 % 5 == 0:\n",
    "        lp1 = p1.tolist()\n",
    "        lp2 = p2.tolist()\n",
    "        rprint(f\"{i1=} {i2=} {lp1=} {lp2=} {dist=:.2f} {tot_dist=:.2f}\")\n",
    "\n",
    "rprint(f\"{i1=} {i2=} {lp1=} {lp2=} {dist=:.2f} {tot_dist=:.2f}\")  # pyright: ignore[reportPossiblyUnboundVariable]\n",
    "# normalize the total distance\n",
    "similarity = tot_dist / max(s1_len, s2_len)\n",
    "rprint(f\"{similarity=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    seg_match.s1_points_transformed[:2],\n",
    "    seg_match.s1_points_transformed[-2:],\n",
    "    seg_match.s2.points[:2],\n",
    "    seg_match.s2.points[-2:],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snap-fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
