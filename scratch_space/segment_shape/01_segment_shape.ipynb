{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match segments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. translate one segment so that the ends are over the first one\n",
    "2. compute some sort of distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from loguru import logger as lg\n",
    "from rich import get_console\n",
    "from rich import print as rprint\n",
    "from rich.console import Console\n",
    "\n",
    "# some magic to make rich work in jupyter\n",
    "# https://github.com/Textualize/rich/issues/3483\n",
    "# enable it for every cell output with %load_ext rich\n",
    "console: Console = get_console()\n",
    "console.is_jupyter = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from snap_fit.config.aruco.aruco_board_config import ArucoBoardConfig\n",
    "from snap_fit.config.aruco.aruco_detector_config import ArucoDetectorConfig\n",
    "from snap_fit.config.types import EDGE_ENDS_TO_CORNER\n",
    "from snap_fit.config.types import EdgePos\n",
    "from snap_fit.config.types import SegmentShape\n",
    "from snap_fit.image.process import estimate_affine_transform\n",
    "from snap_fit.image.process import find_contours\n",
    "from snap_fit.image.process import find_corners\n",
    "from snap_fit.image.process import transform_contour\n",
    "from snap_fit.image.segment import Segment\n",
    "from snap_fit.image.segment_matcher import SegmentMatcher\n",
    "from snap_fit.image.utils import draw_contour\n",
    "from snap_fit.image.utils import draw_corners\n",
    "from snap_fit.image.utils import show_image_mpl\n",
    "from snap_fit.params.snap_fit_params import get_snap_fit_paths\n",
    "from snap_fit.puzzle.piece import Piece\n",
    "from snap_fit.puzzle.sheet import Sheet\n",
    "from snap_fit.puzzle.sheet_aruco import SheetAruco\n",
    "from snap_fit.puzzle.sheet_manager import SheetManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load new data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configure ArUco Board and Detector\n",
    "# Using defaults which match the printed board used for 'data/oca'\n",
    "board_config = ArucoBoardConfig(markers_x=5, markers_y=7)\n",
    "detector_config = ArucoDetectorConfig(board=board_config)\n",
    "\n",
    "# 2. Initialize SheetAruco helper\n",
    "# crop_margin is automatically calculated from the detector configuration\n",
    "sheet_aruco = SheetAruco(detector_config)\n",
    "\n",
    "# 3. Define the loader function\n",
    "# SheetAruco.load_sheet handles loading, rectification, and Sheet creation\n",
    "aruco_loader = sheet_aruco.load_sheet\n",
    "\n",
    "# 4. define base folder\n",
    "paths = get_snap_fit_paths()\n",
    "data_dir = paths.data_fol / \"oca\"\n",
    "lg.info(f\"Loading data from {data_dir}\")\n",
    "\n",
    "# 5. instantiate manager and load\n",
    "manager = SheetManager()\n",
    "manager.add_sheets(folder_path=data_dir, pattern=\"*.jpg\", loader_func=aruco_loader)\n",
    "\n",
    "# Verify Sheets\n",
    "sheets = manager.get_sheets_ls()\n",
    "print(f\"Managed Sheets: {len(sheets)}\")\n",
    "for sheet in sheets:\n",
    "    print(f\" - {sheet.img_fp.name}: {len(sheet.pieces)} pieces\")\n",
    "\n",
    "# Verify Pieces\n",
    "pieces = manager.get_pieces_ls()\n",
    "print(f\"Total Pieces: {len(pieces)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get pieces and segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1_index = 1\n",
    "\n",
    "s1_type = EdgePos.LEFT  # concave in\n",
    "# s1_type = EdgePos.BOTTOM  # convex out\n",
    "# s1_type = EdgePos.RIGHT  # flat edge\n",
    "\n",
    "p1 = pieces[p1_index]\n",
    "rprint(f\"using {p1.name}\")\n",
    "seg1 = p1.contour.segments[s1_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the class now\n",
    "rprint(seg1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_contour_seg = p1.img_bw.copy() // 10\n",
    "for _ei, edge_name in enumerate(EdgePos):\n",
    "    segment = p1.contour.segments[edge_name]\n",
    "    points = segment.points\n",
    "    color = 250 if edge_name == s1_type else 120\n",
    "    draw_contour(img_contour_seg, points, color=color)\n",
    "show_image_mpl(img_contour_seg, figsize=(5, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the contour on x axis\n",
    "source = seg1.coords\n",
    "target = np.array([[0, 0], [0, 500]])\n",
    "transform_matrix = estimate_affine_transform(source, target)\n",
    "\n",
    "# transform the points of the source segment\n",
    "s1_points_transformed = transform_contour(seg1.points, transform_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_contour_seg = p1.img_bw.copy() // 10\n",
    "color = 250\n",
    "draw_contour(\n",
    "    img_contour_seg,\n",
    "    s1_points_transformed + 100,\n",
    "    color=color,\n",
    ")\n",
    "show_image_mpl(img_contour_seg, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_xs = s1_points_transformed[:, 0, 0]\n",
    "# s1_ys\n",
    "\n",
    "flat_th = 20\n",
    "out_count = (s1_xs < -flat_th).sum()\n",
    "in_count = (s1_xs > flat_th).sum()\n",
    "rprint(out_count, in_count)\n",
    "\n",
    "count_th = 5\n",
    "is_out = bool(out_count > count_th)\n",
    "is_in = bool(in_count > count_th)\n",
    "rprint(f\"{is_out=} {is_in=}\")\n",
    "\n",
    "match (is_out, is_in):\n",
    "    case True, False:\n",
    "        segment_shape = SegmentShape.OUT\n",
    "    case False, True:\n",
    "        segment_shape = SegmentShape.IN\n",
    "    case False, False:\n",
    "        segment_shape = SegmentShape.EDGE\n",
    "    case True, True:\n",
    "        segment_shape = SegmentShape.WEIRD\n",
    "\n",
    "rprint(segment_shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snap-fit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
